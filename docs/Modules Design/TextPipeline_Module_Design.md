# TextPipeline â€” Module Design Document
**File:** `text_pipeline.py`  
**Date:** 2025-10-04  
**Language:** Python 3.8+  
**Status:** Stable

---

## 1. Abstract
`TextPipeline` orchestrates a full pass over a user-provided string to produce:
1) a structured explanation of intermediate steps and states, and  
2) a final, endâ€‘user facing HTML rendering with optional warnings.

The pipeline composes five components:
- **RegexTokenizer** â€” emits symbolic tokens (URLs, hashtags, content cues, pronouns, etc.).
- **SpamDFA** â€” counts URLs/hashtags and catches spam phrases; returns `qSpam` or `qSafe`.
- **ContentDFA** â€” combines topic triggers with directionality; returns a final content label (e.g., `qF_Hate`, `qF_Sex`, `qF_Safe`).
- **CensorshipFST** â€” masks disallowed words with `*` while preserving length.
- **WarningFST** â€” maps final labels into short English warning messages.

Only if the DFAs raise any warning state does the pipeline apply the censorship step before rendering the post with `transform_post` (structural formatting and emoji/link/mention/hashtag markup).

---

## 2. Scope and Nonâ€‘Goals
**In scope**
- Deterministic, explainable classification + rendering for a single input string.
- Collection of detailed intermediate artifacts for debugging and audits.
- Conditional censorship based on DFA outcomes.

**Out of scope**
- Batch/stream processing, concurrency primitives, or caching.
- Fuzzy classification, scoring, or policy resolution across multiple labels.
- Persistence, telemetry, or UI delivery; the pipeline returns plain Python data structures.

---

## 3. External Dependencies and Artifacts
- **Internal modules (imported from `src.*`)**
  - `preprocessing.RegexTokenizer` (requires `data/keywords.json`).
  - `spam_dfa.SpamDFA`
  - `content_dfa.ContentDFA`
  - `censorship_fst.CensorshipFST`
  - `warning_fst.WarningFST`
  - `post_processor.transform_post` (HTML rendering).

- **Data file**: `data/keywords.json` (relative to the working directory for the pipelineâ€™s own tokenizer; the DFAs may resolve their own paths internally).

**Environment notes**
- Ensure that the working directory contains `data/keywords.json` (or pass an absolute path into `RegexTokenizer`).  
- Module path consistency: this pipeline expects the referenced modules to be importable under `src.` and to be API-compatible with the signatures in this design.

---

## 4. Public API
### 4.1 Class: `TextPipeline`
**Intent:** Provide a single highâ€‘level entrypoint that performs tokenization, spam and content classification, optional censorship, and HTML rendering, while preserving an audit trail of steps.

**Constructor**
```python
TextPipeline()
```
- Instantiates a `RegexTokenizer("data/keywords.json")` to expose tokens in the audit trail.
- Instantiates `SpamDFA`, `ContentDFA`, `CensorshipFST`, `WarningFST` with their defaults.

**Primary Method (Main Function)**
```python
run(self, text: str) -> dict
```
- **Inputs:** `text` â€” arbitrary Unicode string.
- **Outputs:** A dictionary with two topâ€‘level keys:
  - `"detailed"` â€” full audit record (see Â§5).
  - `"final"` â€” compact result for presentation (see Â§5.2).
- **Determinism:** Same input and configuration yields the same outputs.
- **Complexity:** Overall O(n) in text length; see Â§8.

---

## 5. Data Contracts (Inputs/Outputs)
### 5.1 Detailed trace (`result["detailed"]`)
```jsonc
{
  "tokens":        ["URL","WORD","HASHTAG", ...],
  "spam_state":    "qSpam" | "qSafe",
  "content_state": "qF_Offensive" | "qF_Hate" | "qF_Sex" | "qF_Harass" | "qF_SelfHarm" | "qF_Threats" | "qF_Violence" | "qF_Safe",
  "dfa_warnings":  ["qSpam", "qF_Hate", ...],        // raw DFA terminals that require warnings
  "censored_text": "string",                         // '*' masking if warnings exist; else original text
  "readable_warnings": ["this post may contain ..."],// human messages from WarningFST (None filtered out)
  "final_post":    {
    "text": "<html>...</html>",                      // HTML generated by transform_post
    "enhancements": ["Emoji ':-)' â†’ 'ðŸ˜Š'", "Link detected", ...]
  }
}
```

### 5.2 Final result (`result["final"]`)
```jsonc
{
  "text": "<html>...</html>",
  "enhancements": ["..."],
  "warnings": ["this post may contain spam", "this post may contain hate speech"]
}
```
- Intended for UI delivery without internal state names.

---

## 6. Correctness Arguments
- **Conditional masking:** Censorship is applied only if any DFA indicates a cautionary category; otherwise the original text is rendered, preserving benign content.
- **Explainability:** The pipeline returns both raw terminals (`dfa_warnings`) and human messages (`readable_warnings`), plus the exact token stream and the masked version of text used for rendering.
- **Idempotence of rendering step:** If called repeatedly with the same text and keyword configuration, results are identical.
- **Separation of concerns:** Tokenization, classification, masking, and rendering are independent modules with clear contracts and are composed linearly.

---

## 7. Security & Privacy
- **Output HTML**: The renderer inserts HTML; sanitize or escape untrusted content where necessary. Consider adding `rel="noopener noreferrer"` to external links (see the rendering moduleâ€™s design notes).
- **Masking policy**: Masking is lengthâ€‘preserving and caseâ€‘insensitive as defined by `CensorshipFST`; this avoids leaking the exact word while keeping layout stable.
- **No persistence**: The pipeline does not log or store inputs; callers are responsible for any audit logging or PII handling.

---

## 8. Testing Strategy
### 8.1 Unit tests (pytest)
| ID | Scenario | Input | Expected |
|---|---|---|---|
| T1 | Safe path | `"Hello world!"` | `final.warnings == []`, `final.text` renders original content |
| T2 | Spam via URL count | `"a https://1 https://2 https://3 https://4"` | `spam_state == "qSpam"`, censorship applied, `warnings` contains spam |
| T3 | Spam via phrase | `"free money now"` | `spam_state == "qSpam"`, `warnings` contains spam |
| T4 | Hate via content | `"You are an IDIOT"` | `content_state == "qF_Hate"`, warning message present, censorship applied |
| T5 | Selfâ€‘harm | `"I want to die"` | `content_state == "qF_SelfHarm"`, warning message present |
| T6 | Both spam + hate | mixed text | both warnings present (order deterministic) |
| T7 | Transform integration | text that triggers emojis/links/hashtags | `final.enhancements` includes expected notes |
| T8 | Unknown terminal | force an unknown state | `readable_warnings` filters out `None` |

### 8.2 Golden master
- Freeze a few canonical inputs and assert exact JSON outputs (after normalizing nonâ€‘deterministic fields if any).

### 8.3 Fault injection
- Remove `keywords.json` â†’ expect construction failure (or mock tokenizer to isolate pipeline behavior).
- Force `transform_post` to raise â†’ expect fallback if implemented.

---
## 12. Limitations & Tradeâ€‘offs
- **Multiple tokenizers**: DFAs own their tokenizer configuration internally; the pipeline also exposes its own token list. Divergences can arise if keyword files differ. Prefer dependency injection to share a single lexicon.
- **Binary masking toggle**: Masking is allâ€‘orâ€‘nothing based on presence of warnings; some deployments may prefer to mask only specific categories (e.g., hate but not spam).
- **Ordering of messages**: Current order mirrors the order of collection (spam first, then content). If UX requires deterministic sorting, sort by severity or a fixed index map.


